{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import chainer\n",
    "import matplotlib.pyplot as plt\n",
    "import net_2\n",
    "import numpy as np\n",
    "import os\n",
    "import chainer.functions as F\n",
    "from train_vae_with_specified_label import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths and paramters\n",
    "out_dir_path = './result'\n",
    "log_path = os.path.join(out_dir_path, 'log')\n",
    "model_name = 'model_100.npz'\n",
    "dimz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ld3/W is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-689f167c3d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/chainer/serializers/npz.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file, obj, path, strict)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNpzDeserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/chainer/serializer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/chainer/link.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserializer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/chainer/link.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;31m# Initialize the parameter here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/chainer/serializers/npz.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    140\u001b[0m                     'list of them.')\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ld3/W is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "model = net_2.VAE(784, dimz, 500, F.softplus) \n",
    "chainer.serializers.load_npz(os.path.join(out_dir_path, model_name), model, strict=True)\n",
    "model.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# src_train, src_test = chainer.datasets.get_mnist(withlabel=True) \n",
    "# use binarized mnist\n",
    "TRAIN_PATH = '/root/data/binarized_mnist/train.npy'\n",
    "TEST_PATH = '/root/data/binarized_mnist/test.npy'\n",
    "src_train = np.load(TRAIN_PATH)\n",
    "src_test = np.load(TEST_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specified labels\n",
    "specified_label = 0\n",
    "train = extract_specified_labels(src_train, specified_label)\n",
    "test = extract_specified_labels(src_test, specified_label)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(x, filename):\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi.reshape(28, 28))\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode training dataset\n",
    "train_ind = [1, 3, 5, 10, 2, 0, 13, 15, 17]  \n",
    "x = chainer.Variable(np.asarray(train[train_ind])) \n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode(): \n",
    "    x1 = model(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display and save images\n",
    "print('train')\n",
    "save_images(x.data, os.path.join(out_dir_path, 'train')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('train_reconstructed')\n",
    "save_images(x1.data, os.path.join(out_dir_path, 'train_reconstructed'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see difference between them\n",
    "dx = np.abs(x.data - x1.data)\n",
    "save_images(dx, os.path.join(out_dir_path, 'train_diff')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode test dataset\n",
    "test_ind = [3, 2, 1, 18, 4, 8, 11, 17, 61]\n",
    "x = chainer.Variable(np.asarray(test[test_ind]))\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')    \n",
    "save_images(x.data, os.path.join(out_dir_path, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test reconstructed')\n",
    "save_images(x1.data, os.path.join(out_dir_path, 'test_reconstructed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see difference between them\n",
    "dx = np.abs(x.data - x1.data)\n",
    "save_images(dx, os.path.join(out_dir_path, 'test_diff')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw images from randomly sampled z\n",
    "np.random.seed(1234)\n",
    "z = chainer.Variable(\n",
    "    np.random.normal(0, 1, (9, dimz)).astype(np.float32))\n",
    "x = model.decode(z)\n",
    "save_images(x.data, os.path.join(out_dir_path, 'sampled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(path):\n",
    "    return [float(line) for line in open(path)]\n",
    "\n",
    "import re\n",
    "def loss_generator(path, s):\n",
    "    s = re.compile(r'\"{}\": (-?[0-9]+.[0-9]+),?'.format(s))\n",
    "    for line in open(path):\n",
    "        m = s.findall(line)\n",
    "        if m:\n",
    "            yield float(m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information from log\n",
    "main_loss = list(loss_generator(log_path, 'main/loss'))\n",
    "validation_main_loss = list(loss_generator(log_path, 'validation/main/loss'))\n",
    "main_mu = list(loss_generator(log_path, 'main/mu'))\n",
    "validation_main_mu = list(loss_generator(log_path, 'validation/main/mu'))\n",
    "main_sigma = list(loss_generator(log_path, 'main/sigma'))\n",
    "validation_main_sigma = list(loss_generator(log_path, 'validation/main/sigma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.ylabel('loss', fontsize=20)\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(60, 180)\n",
    "plt.plot(main_loss, label='train')\n",
    "plt.plot(validation_main_loss, label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display mu\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('mu')\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.ylabel('mu', fontsize=20)\n",
    "plt.xlim(0, 100)\n",
    "# plt.ylim(-0.01, 0.01)\n",
    "plt.plot(main_mu, label='train')\n",
    "plt.plot(validation_main_mu, label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sigma\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('sigma')\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.ylabel('sigma', fontsize=20)\n",
    "plt.xlim(0, 100)\n",
    "# plt.ylim(8, 22)\n",
    "plt.plot(main_sigma, label='train')\n",
    "plt.plot(validation_main_sigma, label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(dataset):\n",
    "    ind = [1, 3, 5, 10, 2, 0, 13, 15, 17]  \n",
    "    x = chainer.Variable(np.asarray(dataset[ind])) \n",
    "    with chainer.using_config('train', False), chainer.no_backprop_mode(): \n",
    "        mu, ln_var = model.encode(x) \n",
    "        average_mu = np.mean(mu.data)\n",
    "        sigma = np.exp(ln_var.data/2)\n",
    "        average_sigma = np.mean(sigma)\n",
    "        return average_mu, average_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average mu and sigma for training data\n",
    "mu, sigma = decode(train)\n",
    "print('mu(0): {}'.format(mu))\n",
    "print('sigma(1): {}'.format(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average mu and sigma for test data\n",
    "mu, sigma = decode(test)\n",
    "print('mu(0): {}'.format(mu))\n",
    "print('sigma(1): {}'.format(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像の符号化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1,000 images with label zero, which are considered as normal images\n",
    "zero_number = 1000\n",
    "zeros = train[:zero_number]\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode them\n",
    "xs = chainer.Variable(zeros) \n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode(): \n",
    "    zero_mus, zero_ln_vars = model.encode(xs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 100 images with label six, which are considered as anormaly images\n",
    "anomaly_label = 6\n",
    "sixs = extract_specified_labels(src_train, anomaly_label)[:100]\n",
    "sixs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode them\n",
    "xs = chainer.Variable(sixs) \n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode(): \n",
    "    six_mus, six_ln_vars = model.encode(xs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate normal and anormaly mus\n",
    "dataset = np.concatenate([zero_mus.data, six_mus.data], axis=0)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions\n",
    "reduced_dataset = TSNE(n_components=2, random_state=0).fit_transform(dataset)\n",
    "# reduced_dataset = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into normal and anormaly data\n",
    "zero_reduced_dataset = reduced_dataset[:zero_number]\n",
    "six_reduced_dataset = reduced_dataset[zero_number:]\n",
    "zero_reduced_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mahalanobis distance\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# calculate covariance matrix for training data\n",
    "sigma = np.cov(zero_reduced_dataset, rowvar=False)\n",
    "\n",
    "# make inverse of it\n",
    "inv_sigma = np.linalg.inv(np.cov(zero_reduced_dataset, rowvar=False)) \n",
    "\n",
    "# calculate mean for training data\n",
    "mean = np.mean(zero_reduced_dataset, axis=0)\n",
    "\n",
    "# calculate mahalanobis distances\n",
    "outlier_dists = [mahalanobis(mean, outlier, inv_sigma) for outlier in six_reduced_dataset]\n",
    "inlier_dists = [mahalanobis(mean, inlier, inv_sigma) for inlier in zero_reduced_dataset]\n",
    "\n",
    "average_outlier_dist = np.mean(outlier_dists)\n",
    "average_inlier_dist = np.mean(inlier_dists)\n",
    "print('average_outlier_dist', average_outlier_dist)\n",
    "print('average_inlier_dist', average_inlier_dist)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(reduced_dataset[:zero_number, 0], reduced_dataset[:zero_number, 1], c='blue', edgecolors='blue', label='zero', marker='o')\n",
    "plt.scatter(reduced_dataset[zero_number:, 0], reduced_dataset[zero_number:, 1], c='green', edgecolors='green', label='six', marker='o')\n",
    "plt.axis('equal')\n",
    "\n",
    "\n",
    "n = 100\n",
    "x = np.linspace(-60, 60)\n",
    "y = np.linspace(-60, 60)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.empty((n//2, n//2))\n",
    "for r  in range(n // 2):\n",
    "    for c in range(n // 2):\n",
    "        v = np.c_[X[r, c], Y[r, c]]\n",
    "        Z[r, c] = mahalanobis(mean, v, inv_sigma)\n",
    "\n",
    "plt.contour(X, Y, np.array(Z), levels=[1, 2, 3, 4])\n",
    "\n",
    "plt.xlim(-60, 60)\n",
    "plt.ylim(-60, 60)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display F values\n",
    "plt.figure(figsize=(10, 5))\n",
    "thrs = []\n",
    "fs = []\n",
    "prs = []\n",
    "res = []\n",
    "with open('./f_value.txt') as fin:\n",
    "    for line in fin:\n",
    "        thr, f, pr, re = [float(item) for item in line.strip().split()]\n",
    "        thrs.append(thr)\n",
    "        fs.append(f)\n",
    "        prs.append(pr)\n",
    "        res.append(re)\n",
    "plt.xlabel('threshold', fontsize=20)\n",
    "plt.plot(thrs, res, marker='.', label='Recall')\n",
    "plt.plot(thrs, fs, marker='.', label='F value')\n",
    "plt.plot(thrs, prs, marker='.', label='Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像の符号化・復号化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_label = 6\n",
    "random_sixs = extract_specified_labels(src_train, anomaly_label)[:9]\n",
    "random_sixs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = chainer.Variable(random_sixs)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 差をとる。\n",
    "dx = np.abs(x.data - x1.data)\n",
    "save_images(dx, os.path.join(out_dir_path, 'six_diff')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
